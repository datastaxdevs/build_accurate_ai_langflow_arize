{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure accuracy of agentic app with Arize and Langflow\n",
    "\n",
    "In this notebook we'll step through how to use open source tools [Arize](https://arize.com/) and [Langflow](https://www.langflow.org/) and to measure the accuracy of an agentic application.\n",
    "\n",
    "## Prepping a Dataset\n",
    "\n",
    "Let's start by gathering some example data from a standard question and answer benchmark. We'll use the Standford Question Answering Dataset (SQuAD).\n",
    "\n",
    "Available at [https://rajpurkar.github.io/SQuAD-explorer/](https://rajpurkar.github.io/SQuAD-explorer/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully\n",
      "Dataset loaded with 35 articles\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Download the file\n",
    "url = 'https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the download was successful\n",
    "if response.status_code == 200:\n",
    "    # Save the file locally\n",
    "    with open('dev-v2.0.json', 'w') as file:\n",
    "        json.dump(response.json(), file)\n",
    "    print(\"File downloaded successfully\")\n",
    "    \n",
    "    # Load the data\n",
    "    data = response.json()\n",
    "    print(f\"Dataset loaded with {len(data['data'])} articles\")\n",
    "else:\n",
    "    print(f\"Failed to download file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all articles from the dataset\n",
    "docs = []\n",
    "for record in data[\"data\"]:\n",
    "    text = \"\"\n",
    "    for paragraph in record[\"paragraphs\"]:\n",
    "        text += paragraph[\"context\"] + \"\\n\"\n",
    "    docs.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wikipedia articles in dataset: 35.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of wikipedia articles in dataset: {len(docs)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create markdown files for each article for use in Langflow UI\n",
    "for i, doc in enumerate(docs):\n",
    "    filename = f\"data/markdown_files/article_{i}.md\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all questions and answers for each article\n",
    "qandas = []\n",
    "for record in data[\"data\"]:\n",
    "    for paragraph in record[\"paragraphs\"]:\n",
    "        for qa in paragraph[\"qas\"]:\n",
    "            if len(qa[\"answers\"]) > 0:\n",
    "                qandas.append((qa[\"question\"], qa[\"answers\"][0][\"text\"]))\n",
    "\n",
    "# there are about 6000 Q&A pairs in this data set.  \n",
    "# Let's shorten to 100 to make it easier to run our tests\n",
    "import random\n",
    "samples = random.sample(qandas, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What type of fossils were found in China?', 'Cambrian sessile frond-like fossil Stromatoveris')\n",
      "('Where do pharmacists acquire more preparation following pharmacy school?', 'a pharmacy practice residency')\n",
      "('What contributed to the decreased inequality between trained and untrained workers?', 'period of compression')\n"
     ]
    }
   ],
   "source": [
    "# Let's look at a couple examples of questions and answers\n",
    "print(samples[0])\n",
    "print(samples[1])\n",
    "print(samples[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install modules needed for the rest of this example\n",
    "\n",
    "We'll need the following modules to be available\n",
    "\n",
    "- `langflow` for rapidly designing AI workflows\n",
    "- `arize` to run evals\n",
    "- `pandas` to format the data\n",
    "- `openai` for access to LLMs and embedding models\n",
    "\n",
    "If you don't already have these installed, go ahead and run the install commands below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uv requires a virtual environment to run\n",
    "!uv venv\n",
    "!source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install all the modules for the rest of the notebook\n",
    "!uv pip install langflow pandas openai arize -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our ground truth data to Arize\n",
    "\n",
    "Now that we have a set of questions and answers, we can use this to evaluate the quality of our agentic application.\n",
    "\n",
    "Let's upload this dataset to Phoenix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start by creating a dataframe with our Q&A pairs and save a copy\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(samples, columns=[\"question\", \"answer\"])\n",
    "\n",
    "# only run this line if you want to resave the dataframe\n",
    "df.to_csv(\"data/qa_pairs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What type of fossils were found in China?</td>\n",
       "      <td>Cambrian sessile frond-like fossil Stromatoveris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where do pharmacists acquire more preparation following pharmacy school?</td>\n",
       "      <td>a pharmacy practice residency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What contributed to the decreased inequality between trained and untrained workers?</td>\n",
       "      <td>period of compression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              question  \\\n",
       "0                                            What type of fossils were found in China?   \n",
       "1             Where do pharmacists acquire more preparation following pharmacy school?   \n",
       "2  What contributed to the decreased inequality between trained and untrained workers?   \n",
       "\n",
       "                                             answer  \n",
       "0  Cambrian sessile frond-like fossil Stromatoveris  \n",
       "1                     a pharmacy practice residency  \n",
       "2                             period of compression  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# or just load from the csv provided\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/qa_pairs.csv\")\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  arize.utils.logging | WARNING | DEPRECATED: developer_key is deprecated, only api_key is needed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# get the Arize client\n",
    "# now let's create a dataset in Arize\n",
    "from arize.experimental.datasets import ArizeDatasetsClient\n",
    "from arize.experimental.datasets.utils.constants import GENERATIVE\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "ARIZE_API_KEY = os.getenv(\"ARIZE_API_KEY\")\n",
    "ARIZE_SPACE_ID = os.getenv(\"ARIZE_SPACE_ID\")\n",
    "ARIZE_DEVELOPER_KEY = os.getenv(\"ARIZE_DEVELOPER_KEY\")\n",
    "\n",
    "arize_client = ArizeDatasetsClient(api_key=ARIZE_API_KEY, developer_key=ARIZE_DEVELOPER_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  arize.utils.logging | WARNING | DEPRECATED: developer_key is deprecated, only api_key is needed.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro.cantarero/.pyenv/versions/3.12.10/envs/langflow-dev-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# create the dataset in Arize\n",
    "dataset_id = arize_client.create_dataset(\n",
    "    space_id=ARIZE_SPACE_ID, \n",
    "    dataset_name=\"squad_dataset\",\n",
    "    dataset_type=GENERATIVE,\n",
    "    data=df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for speed, let's also make a smaller dataset\n",
    "df_small = df.head(20)\n",
    "dataset = arize_client.create_dataset(\n",
    "    data=df_small,\n",
    "    dataset_name=\"squad-dev-v2.0-x-small\",\n",
    "    space_id=ARIZE_SPACE_ID,\n",
    "    dataset_type=GENERATIVE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Langflow Flows from code\n",
    "\n",
    "In this section, we define a method to use the Langflow runtime to execute flows and return the results.\n",
    "\n",
    "You can find details on how to call these methods by clicking the **Publish** button in the upper right corner of the Langflow UI when a flow is open and you are editing it.  Then select **API Access**.\n",
    "\n",
    "The code below assumes you are running Langflow locally on your machine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to run a flow in Langflow\n",
    "# trigger flow via API\n",
    "import requests\n",
    "import uuid\n",
    "\n",
    "BASE_API_URL = \"http://127.0.0.1:7860\"\n",
    "\n",
    "def run_flow(input: str, flow_id: str, input_type: str = \"chat\", tweaks: dict = None):\n",
    "    \"\"\" Raises exceptions for non-200 status code from langflow response\n",
    "    \"\"\"\n",
    "    api_url = f\"{BASE_API_URL}/api/v1/run/{flow_id}\"\n",
    "\n",
    "    payload = {\n",
    "        \"input_value\": input,\n",
    "        \"output_type\": \"chat\",\n",
    "        \"input_type\": input_type,\n",
    "        \"session_id\": str(uuid.uuid4()), # create a new session to avoid chat history\n",
    "    }\n",
    "\n",
    "    if tweaks:\n",
    "        payload[\"tweaks\"] = tweaks\n",
    "\n",
    "    timeout = 25\n",
    "    attempts = 6\n",
    "    for i in range(attempts):\n",
    "        try:\n",
    "            response = requests.post(api_url, json=payload, timeout=timeout)\n",
    "            if response.status_code != 200:\n",
    "                raise requests.exceptions.RequestException(f\"Status code: {response.status_code}\")\n",
    "            return response\n",
    "        \n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"The flow request timed out. Attempt {i}, current timeout {timeout}.\")\n",
    "            timeout *= 2\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(e)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run an experiment with Langflow and Arize\n",
    "\n",
    "1. Define a task to run the the a flow on the dataset\n",
    "2. Create an LLM to act as a judge\n",
    "3. Define an evaluator to measure the accuracy of the results\n",
    "4. Run the experiment and log the results to Arize Phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_FLOW_ID = \"796625a6-2526-4e12-b2f8-873d66940016\"\n",
    "TWEAKS = {}\n",
    "\n",
    "def task(dataset_row) -> str:\n",
    "    question = dataset_row[\"question\"]\n",
    "    response = run_flow(question, CHAT_FLOW_ID, tweaks=TWEAKS)\n",
    "    text = response.json()['outputs'][0]['outputs'][0]['results']['message'][\"text\"]\n",
    "    return text   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.evals.models import OpenAIModel\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "judge_model = OpenAIModel(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "from phoenix.evals import (\n",
    "    QA_PROMPT_RAILS_MAP,\n",
    "    QA_PROMPT_TEMPLATE,\n",
    "    OpenAIModel,\n",
    "    llm_classify,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are given a question, an answer and reference text. You must determine whether the\n",
      "given answer correctly answers the question based on the reference text. Here is the data:\n",
      "    [BEGIN DATA]\n",
      "    ************\n",
      "    [Question]: {input}\n",
      "    ************\n",
      "    [Reference]: {reference}\n",
      "    ************\n",
      "    [Answer]: {output}\n",
      "    [END DATA]\n",
      "Your response must be a single word, either \"correct\" or \"incorrect\",\n",
      "and should not contain any text or characters aside from that word.\n",
      "\"correct\" means that the question is correctly and fully answered by the answer.\n",
      "\"incorrect\" means that the question is not correctly or only partially answered by the\n",
      "answer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's look at the prompt template\n",
    "print(QA_PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from phoenix.experiments.evaluators import create_evaluator\n",
    "from arize.experimental.datasets.experiments.evaluators.base import EvaluationResult\n",
    "import pandas as pd\n",
    "\n",
    "#@create_evaluator(name=\"Answer Correctness\", kind=\"LLM\")\n",
    "def answer_correctness(input, output, dataset_row) -> EvaluationResult:\n",
    "\n",
    "    question = dataset_row[\"question\"]\n",
    "    answer = dataset_row[\"answer\"]\n",
    "    df_in = pd.DataFrame({\n",
    "        \"input\": question,\n",
    "        \"output\": output,\n",
    "        \"reference\": answer,\n",
    "    }, index=[0])\n",
    "              \n",
    "    rails = list(QA_PROMPT_RAILS_MAP.values())\n",
    "    \n",
    "    eval_df = llm_classify(\n",
    "        data=df_in,\n",
    "        template=QA_PROMPT_TEMPLATE,\n",
    "        model=judge_model,\n",
    "        rails=rails,\n",
    "        provide_explanation=True,\n",
    "        run_sync=True,\n",
    "    )\n",
    "    \n",
    "    label = eval_df[\"label\"][0]\n",
    "    explanation = eval_df[\"explanation\"][0]\n",
    "    score = 1 if label == \"correct\" else 0\n",
    "\n",
    "    return EvaluationResult(label=label, score=score, explanation=explanation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset IDs - get these from the Arize UI\n",
    "squad_qa_20 = \"RGF0YXNldDozNDMxNjowWFIx\"  \n",
    "squad_qa_100 = \"RGF0YXNldDozNDMxNTpSZ21u\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m  arize.utils.logging | INFO | 🧪 Experiment started.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🐌!! If running inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n",
      "running tasks |          | 0/20 (0.0%) | ⏳ 00:00<? | ?it/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The flow request timed out. Attempt 0, current timeout 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running tasks |████      | 8/20 (40.0%) | ⏳ 00:49<00:53 |  4.49s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The flow request timed out. Attempt 0, current timeout 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running tasks |██████████| 20/20 (100.0%) | ⏳ 02:01<00:00 |  6.07s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m  arize.utils.logging | INFO | ✅ Task runs completed.\n",
      "Tasks Summary (04/29/25 04:01 PM -0700)\n",
      "---------------------------------------\n",
      "|   n_examples |   n_runs |   n_errors |\n",
      "|-------------:|---------:|-----------:|\n",
      "|           20 |       20 |          0 |\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "🐌!! If running inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.57s/it? | ?it/s\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.56s/it00:31 |  1.66s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.22s/it<00:29 |  1.65s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.39s/it<00:25 |  1.50s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.25s/it<00:24 |  1.50s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.33s/it<00:21 |  1.44s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.14s/it<00:20 |  1.43s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.36s/it<00:17 |  1.37s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.38s/it<00:16 |  1.39s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.78s/it<00:15 |  1.42s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.66s/it4<00:15 |  1.56s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:05<00:00 |  5.97s/it6<00:14 |  1.61s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.65s/it2<00:23 |  2.97s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.29s/it4<00:18 |  2.60s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.36s/it5<00:13 |  2.23s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:00<00:00 |  1.02it/s7<00:09 |  1.99s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.45s/it8<00:06 |  1.71s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.75s/it9<00:04 |  1.66s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.54s/it1<00:03 |  1.71s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.17s/it3<00:01 |  1.69s/it\n",
      "running experiment evaluations |██████████| 20/20 (100.0%) | ⏳ 00:34<00:00 |  1.73s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m  arize.utils.logging | INFO | ✅ All evaluators completed.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('RXhwZXJpbWVudDo5OTg0OmNhWVE=',\n",
       "                id                            example_id  \\\n",
       " 0   EXP_ID_e5570c  fd618731-c84c-4b19-a3cc-1926cfaf46e9   \n",
       " 1   EXP_ID_ddc0f7  cb30a0b3-25fc-4e02-83ef-d24e0854bfe0   \n",
       " 2   EXP_ID_1262a8  652d1890-e423-48d4-82fb-f6b81aec92d2   \n",
       " 3   EXP_ID_0f323c  ca6ebe6d-14b8-4636-9248-73bc5e600a2a   \n",
       " 4   EXP_ID_1727ab  e210d864-6a21-4988-800e-6bd2b584dcc8   \n",
       " 5   EXP_ID_39234c  5b7a3b5d-8c68-4796-a2cf-6f14c3cc4f4a   \n",
       " 6   EXP_ID_acc5f4  48a4e6eb-205e-4574-808c-e92d59640f84   \n",
       " 7   EXP_ID_3a5b8a  b025e287-4ad4-43bd-8255-56f185832e92   \n",
       " 8   EXP_ID_4caef2  768a00d8-56a5-496a-b42b-d131ed10d3e8   \n",
       " 9   EXP_ID_8a95fb  551de8b8-5b29-47dd-a76e-49f95ad528ed   \n",
       " 10  EXP_ID_adc3e7  4b1762ff-b7af-4e46-b6b8-1bc4f4284d39   \n",
       " 11  EXP_ID_d18163  b1f7b3ff-dee6-4040-8f8a-75719fef3cff   \n",
       " 12  EXP_ID_43e51a  9e0975bf-5989-4da1-8088-86dc6a88a69b   \n",
       " 13  EXP_ID_9c7699  165c43f8-1ea6-4f2d-99b4-b81b32640da5   \n",
       " 14  EXP_ID_8c87d5  e0089d72-aabb-4f96-bf65-2e6d9c4d75cc   \n",
       " 15  EXP_ID_d9f1eb  e2ee72bd-a0b4-40f9-b67a-2c380a81d60d   \n",
       " 16  EXP_ID_ab687b  541d687a-fe81-43e6-9b9b-5e5719f89af5   \n",
       " 17  EXP_ID_650cf4  2d6f9618-1dac-4c22-b107-83f7a3a593f3   \n",
       " 18  EXP_ID_6e8cd8  2d128e1b-ef9b-4735-87b4-4c7494299e62   \n",
       " 19  EXP_ID_faaea2  41481fb4-8b84-497c-bca8-75def669a4fc   \n",
       " \n",
       "                                                result  \\\n",
       " 0   In China, significant fossils such as the earl...   \n",
       " 1   Pharmacists acquire more preparation following...   \n",
       " 2   The decreased inequality between trained and u...   \n",
       " 3   In South Carolina, Huguenot nobility primarily...   \n",
       " 4   It is now possible to convert old relative age...   \n",
       " 5     Thomas B. Edsall is a journalist and professor.   \n",
       " 6   In bars, oxygen is used as a euphoric enhancem...   \n",
       " 7            I don't have access to that information.   \n",
       " 8   Warsaw was ranked as the 32nd most livable cit...   \n",
       " 9   The Merwede-Oude Maas, along with the Waal and...   \n",
       " 10  The Intergovernmental Panel on Climate Change ...   \n",
       " 11  A complex net of contracts and other legal obl...   \n",
       " 12  When workers work harder, it can lead to incre...   \n",
       " 13  The section of the Rhine Gorge recognized by U...   \n",
       " 14  BSkyB initially competed with British Satellit...   \n",
       " 15  The Dutch document that condemned the Spanish ...   \n",
       " 16  The first self-sustained man-made nuclear reac...   \n",
       " 17  The Six Ministries existed during the imperial...   \n",
       " 18     There are 11 megaregions in the United States.   \n",
       " 19  The rainforest is home to an estimated 438,000...   \n",
       " \n",
       "                      result.trace.id  result.trace.timestamp  \\\n",
       " 0   872360b1648bb99806db92e345f38a86           1745967547202   \n",
       " 1   b39fb8c5885390daec3dd095edb02132           1745967566605   \n",
       " 2   3f55bc4dede0daba6a3d21266ae64a16           1745967570298   \n",
       " 3   746ef664bad94fbef0cd9b366c455d6c           1745967574841   \n",
       " 4   7a8cb0b8d5f7a8aad8db04d7c7082d7f           1745967578514   \n",
       " 5   bb220a928218ffe3b58c9d679dae12fc           1745967583287   \n",
       " 6   083b847b7b551fcc3931a14d6149fe40           1745967587150   \n",
       " 7   0bbf4a93bd4d97e96b0eb8137afc2b92           1745967591956   \n",
       " 8   bae6983645ac044e141bb4239a6c4d60           1745967595417   \n",
       " 9   b2523989a80177038daeafb8b4198630           1745967616489   \n",
       " 10  be380dcc2621966314080da61eed38c2           1745967621074   \n",
       " 11  2719260fdadf601eb09cf01a4e7d5d6b           1745967625168   \n",
       " 12  4374dd6d2c1c138314a7949c259461b3           1745967630168   \n",
       " 13  21ecf19a2a6d47911d78569dce684434           1745967635125   \n",
       " 14  d751352377f1a35525de4222a9417952           1745967639324   \n",
       " 15  f068b96370b3e63aaccacb0a5f97991e           1745967643270   \n",
       " 16  677e7d97deb7359d18a6a423541166c7           1745967647305   \n",
       " 17  38f502bbde3f168a82257e57cd3ad87b           1745967650855   \n",
       " 18  4e8581198bcdc83030007f84d8b29272           1745967654726   \n",
       " 19  e1bec923296d29b360c21cccbc05b523           1745967658195   \n",
       " \n",
       "     eval.answer_correctness.score eval.answer_correctness.label  \\\n",
       " 0                               1                       correct   \n",
       " 1                               0                     incorrect   \n",
       " 2                               1                       correct   \n",
       " 3                               1                       correct   \n",
       " 4                               1                       correct   \n",
       " 5                               1                       correct   \n",
       " 6                               1                       correct   \n",
       " 7                               0                     incorrect   \n",
       " 8                               1                       correct   \n",
       " 9                               0                     incorrect   \n",
       " 10                              1                       correct   \n",
       " 11                              0                     incorrect   \n",
       " 12                              1                       correct   \n",
       " 13                              1                       correct   \n",
       " 14                              1                       correct   \n",
       " 15                              0                     incorrect   \n",
       " 16                              1                       correct   \n",
       " 17                              1                       correct   \n",
       " 18                              1                       correct   \n",
       " 19                              0                     incorrect   \n",
       " \n",
       "                   eval.answer_correctness.explanation  \\\n",
       " 0   The question asks about the type of fossils fo...   \n",
       " 1   The question asks where pharmacists acquire mo...   \n",
       " 2   The question asks what contributed to the decr...   \n",
       " 3   To determine if the answer is correct, we firs...   \n",
       " 4   To determine if the answer is correct, we firs...   \n",
       " 5   To determine if the answer is correct, we firs...   \n",
       " 6   The question asks how oxygen is used in bars a...   \n",
       " 7   The question asks when the French learned abou...   \n",
       " 8   To determine if the answer is correct, we firs...   \n",
       " 9   The question asks what the Merwede-Oude Maas f...   \n",
       " 10  The question asks what the IPCC relies on for ...   \n",
       " 11  To determine if the answer correctly addresses...   \n",
       " 12  To determine if the answer correctly addresses...   \n",
       " 13  The question asks for the specific name of the...   \n",
       " 14  The question asks who BSkyB initially competed...   \n",
       " 15  The question asks for the Dutch document that ...   \n",
       " 16  To determine if the answer is correct, we firs...   \n",
       " 17  The question asks when the Six Ministries exis...   \n",
       " 18  To determine if the answer is correct, we firs...   \n",
       " 19  The question asks for the total number of plan...   \n",
       " \n",
       "     eval.answer_correctness.trace.id  eval.answer_correctness.trace.timestamp  \n",
       " 0   b280c5b96888fed2814b2e2776994133                            1745967667536  \n",
       " 1   8c06efe9df1b192e712576fa5b2e4c4b                            1745967669193  \n",
       " 2   56ad9857e17b597557952a33af3ee7d5                            1745967670838  \n",
       " 3   023f2b35811f9ceec0a2a5a013308353                            1745967672150  \n",
       " 4   6c9f121335f381397d5742a80754a58d                            1745967673659  \n",
       " 5   1a38d3f68422d3e983ff2ce0d6043a31                            1745967674997  \n",
       " 6   fee9537bd7d63d1e8f1114b8d6870463                            1745967676414  \n",
       " 7   da45b78cb8a53dd7e3bd898ae4090507                            1745967677642  \n",
       " 8   c017fb4b13ef72204c3030dbce8eb175                            1745967679076  \n",
       " 9   a8efbe09431e0d1efcb9c91326da5e3a                            1745967680563  \n",
       " 10  b59a1af2f947a1bdba3d1a7009a83c2b                            1745967682428  \n",
       " 11  c177a4831f7bb889ab1632d9190db62e                            1745967684172  \n",
       " 12  68018db4687aa40395946537e0e5bccf                            1745967690241  \n",
       " 13  f87e64405b18884173ae71d03c7f8623                            1745967691976  \n",
       " 14  09de57b78a7980af71c0c3b795533d02                            1745967693361  \n",
       " 15  ff65d6f0ee80c5469f101f43d346ab5e                            1745967694810  \n",
       " 16  e54f05a8daded6574ee58a6cad59d2bb                            1745967695875  \n",
       " 17  970a711908583e038f878c671699ad01                            1745967697409  \n",
       " 18  25ffe79f0a474bf9d3bbf3e48fb2d36e                            1745967699250  \n",
       " 19  4e8f136cb3e791f190e2f9a6f2a44a10                            1745967700875  )"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arize_client.run_experiment(\n",
    "    space_id=ARIZE_SPACE_ID,\n",
    "    dataset_id=squad_qa_20,\n",
    "    task=task,\n",
    "    evaluators=[answer_correctness],\n",
    "    experiment_name=\"astra_v3_small_n1_gpt4o_concise\",\n",
    "    exit_on_error=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the flow from code instead of in the Langflow frontend\n",
    "\n",
    "We can also script changes to flows so we can write a batch of tests to try out many different configurations.\n",
    "\n",
    "In this case, we'll change the LLM used by the Orchestrating Agent to `gpt-4.1-mini`.\n",
    "\n",
    "In Langflow, you can find this by clicking the **Publish** button in the upper right, then selecting **API access** and then clicking the **Tweaks** button.\n",
    "\n",
    "Select the components you want to modify, and then close the Tweaks section to see updated code to call the API with these changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![How to set tweaks](img/tweaks_ide.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m  arize.utils.logging | INFO | 🧪 Experiment started.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🐌!! If running inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n",
      "running tasks |██████████| 20/20 (100.0%) | ⏳ 02:36<00:00 |  7.81s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m  arize.utils.logging | INFO | ✅ Task runs completed.\n",
      "Tasks Summary (04/29/25 04:43 PM -0700)\n",
      "---------------------------------------\n",
      "|   n_examples |   n_runs |   n_errors |\n",
      "|-------------:|---------:|-----------:|\n",
      "|           20 |       20 |          0 |\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "🐌!! If running inside a notebook, patching the event loop with nest_asyncio will allow asynchronous eval submission, and is significantly faster. To patch the event loop, run `nest_asyncio.apply()`.\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.27s/it? | ?it/s\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.14s/it00:26 |  1.39s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.19s/it<00:23 |  1.31s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.07s/it<00:21 |  1.29s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.42s/it<00:19 |  1.24s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.30s/it<00:20 |  1.34s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.49s/it<00:19 |  1.36s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.47s/it<00:18 |  1.43s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.41s/it<00:17 |  1.47s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.46s/it<00:16 |  1.49s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.72s/it4<00:15 |  1.51s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.25s/it6<00:14 |  1.60s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:04<00:00 |  4.93s/it7<00:12 |  1.52s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.24s/it2<00:18 |  2.58s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.47s/it3<00:13 |  2.20s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.38s/it5<00:10 |  2.01s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.37s/it6<00:07 |  1.85s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:05<00:00 |  5.47s/it8<00:05 |  1.73s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.24s/it3<00:05 |  2.88s/it\n",
      "llm_classify |██████████| 1/1 (100.0%) | ⏳ 00:01<00:00 |  1.14s/it5<00:02 |  2.42s/it\n",
      "running experiment evaluations |██████████| 20/20 (100.0%) | ⏳ 00:36<00:00 |  1.82s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m  arize.utils.logging | INFO | ✅ All evaluators completed.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('RXhwZXJpbWVudDo5OTk1OnBQY1Q=',\n",
       "                id                            example_id  \\\n",
       " 0   EXP_ID_bceea2  fd618731-c84c-4b19-a3cc-1926cfaf46e9   \n",
       " 1   EXP_ID_2af667  cb30a0b3-25fc-4e02-83ef-d24e0854bfe0   \n",
       " 2   EXP_ID_6f452c  652d1890-e423-48d4-82fb-f6b81aec92d2   \n",
       " 3   EXP_ID_8ffdd6  ca6ebe6d-14b8-4636-9248-73bc5e600a2a   \n",
       " 4   EXP_ID_abd09a  e210d864-6a21-4988-800e-6bd2b584dcc8   \n",
       " 5   EXP_ID_3bc1fa  5b7a3b5d-8c68-4796-a2cf-6f14c3cc4f4a   \n",
       " 6   EXP_ID_daa7c7  48a4e6eb-205e-4574-808c-e92d59640f84   \n",
       " 7   EXP_ID_34b6e5  b025e287-4ad4-43bd-8255-56f185832e92   \n",
       " 8   EXP_ID_acaf12  768a00d8-56a5-496a-b42b-d131ed10d3e8   \n",
       " 9   EXP_ID_73fecf  551de8b8-5b29-47dd-a76e-49f95ad528ed   \n",
       " 10  EXP_ID_292c23  4b1762ff-b7af-4e46-b6b8-1bc4f4284d39   \n",
       " 11  EXP_ID_5d8461  b1f7b3ff-dee6-4040-8f8a-75719fef3cff   \n",
       " 12  EXP_ID_b030c0  9e0975bf-5989-4da1-8088-86dc6a88a69b   \n",
       " 13  EXP_ID_b75547  165c43f8-1ea6-4f2d-99b4-b81b32640da5   \n",
       " 14  EXP_ID_185367  e0089d72-aabb-4f96-bf65-2e6d9c4d75cc   \n",
       " 15  EXP_ID_34fa8b  e2ee72bd-a0b4-40f9-b67a-2c380a81d60d   \n",
       " 16  EXP_ID_cfe862  541d687a-fe81-43e6-9b9b-5e5719f89af5   \n",
       " 17  EXP_ID_f384c3  2d6f9618-1dac-4c22-b107-83f7a3a593f3   \n",
       " 18  EXP_ID_503cfe  2d128e1b-ef9b-4735-87b4-4c7494299e62   \n",
       " 19  EXP_ID_c29d41  41481fb4-8b84-497c-bca8-75def669a4fc   \n",
       " \n",
       "                                                result  \\\n",
       " 0   Fossils found in China include the early Cambr...   \n",
       " 1   Pharmacists acquire more preparation following...   \n",
       " 2   The decreased inequality between trained and u...   \n",
       " 3   Huguenot nobility settled in the Charleston Or...   \n",
       " 4   It is now possible to convert old relative age...   \n",
       " 5            I don't have access to that information.   \n",
       " 6   Oxygen is used in bars, specifically oxygen ba...   \n",
       " 7   The French learned about Braddock's plans well...   \n",
       " 8   Warsaw was ranked as the 32nd most liveable ci...   \n",
       " 9   The Merwede-Oude Maas, together with the Waal ...   \n",
       " 10  The IPCC relies on assessing available informa...   \n",
       " 11  A complex net of contracts and other legal obl...   \n",
       " 12  Workers working harder can increase productivi...   \n",
       " 13  The section of the Rhine Gorge recognized by U...   \n",
       " 14  BSkyB initially competed with the ONdigital (l...   \n",
       " 15  The Dutch document that condemned the Spanish ...   \n",
       " 16  The name of the first self-sustained man-made ...   \n",
       " 17  The Six Ministries had existed since the Sui a...   \n",
       " 18     There are 11 megaregions in the United States.   \n",
       " 19  The total number of plant species in the rainf...   \n",
       " \n",
       "                      result.trace.id  result.trace.timestamp  \\\n",
       " 0   41555c0b535b85634046b1d9ea6cca64           1745970080075   \n",
       " 1   616fc2e9c5c22cbd5bd71cc6f29cc545           1745970090016   \n",
       " 2   06f8b31d5f5676f64b7bcae61aa816b9           1745970097869   \n",
       " 3   0992a52eb6fe31479bc047632ea6f75f           1745970106912   \n",
       " 4   320bdc4fcce0341061e0454b8c475244           1745970114361   \n",
       " 5   510ae24238c4d87a4728e4fcf52b0d36           1745970123909   \n",
       " 6   b0053cdb14949cdf9a2828db55d86618           1745970130150   \n",
       " 7   20ddbb37f8f9ba9c11eedc6a5f7551a8           1745970136956   \n",
       " 8   b1bc66db7d5da47eac782738f99a1171           1745970144544   \n",
       " 9   c4e7e42b3e338221342ca3c5b934b549           1745970151645   \n",
       " 10  e48c30d46050591ddfa484b497f43a45           1745970160370   \n",
       " 11  4576668889abdc7d838bdc04f7c5e877           1745970168590   \n",
       " 12  3a3ba363fd4a469ce6dc7fd897adb9aa           1745970176027   \n",
       " 13  4b014286932992516a7f9541cd28d95b           1745970183775   \n",
       " 14  b52976226b54aa33fce8b2d424c3f52b           1745970192691   \n",
       " 15  e80b1a60723de1c38ac805d7cfe17bc1           1745970199935   \n",
       " 16  36264659c4ea4c22e0507c064ca94138           1745970207891   \n",
       " 17  79797537a8ffb72542c0ada479de4cc0           1745970214220   \n",
       " 18  5a530a4e8d9bb7395749157fc3d92a9f           1745970220116   \n",
       " 19  8d624220870dda363ec2cae29cc21838           1745970226713   \n",
       " \n",
       "     eval.answer_correctness.score eval.answer_correctness.label  \\\n",
       " 0                               1                       correct   \n",
       " 1                               1                       correct   \n",
       " 2                               1                       correct   \n",
       " 3                               1                       correct   \n",
       " 4                               1                       correct   \n",
       " 5                               0                     incorrect   \n",
       " 6                               1                       correct   \n",
       " 7                               1                       correct   \n",
       " 8                               1                       correct   \n",
       " 9                               1                       correct   \n",
       " 10                              1                       correct   \n",
       " 11                              1                       correct   \n",
       " 12                              1                       correct   \n",
       " 13                              1                       correct   \n",
       " 14                              1                       correct   \n",
       " 15                              1                       correct   \n",
       " 16                              1                       correct   \n",
       " 17                              1                       correct   \n",
       " 18                              1                       correct   \n",
       " 19                              1                       correct   \n",
       " \n",
       "                   eval.answer_correctness.explanation  \\\n",
       " 0   The answer provides specific examples of fossi...   \n",
       " 1   The question asks where pharmacists acquire mo...   \n",
       " 2   The answer provides a detailed explanation of ...   \n",
       " 3   The answer states that Huguenot nobility settl...   \n",
       " 4   To determine if the answer is correct, we firs...   \n",
       " 5   The question asks for Thomas B. Edsall's profe...   \n",
       " 6   The question asks how oxygen is used in bars, ...   \n",
       " 7   To determine if the answer is correct, we firs...   \n",
       " 8   To determine if the answer is correct, we firs...   \n",
       " 9   To determine if the answer is correct, we firs...   \n",
       " 10  To determine if the answer is correct, we firs...   \n",
       " 11  The answer provides a clear definition of what...   \n",
       " 12  The question asks about the impact of workers ...   \n",
       " 13  The question asks for the name of the section ...   \n",
       " 14  To determine if the answer is correct, we firs...   \n",
       " 15  To determine if the answer is correct, we firs...   \n",
       " 16  To determine if the answer is correct, we firs...   \n",
       " 17  The question asks when the Six Ministries exis...   \n",
       " 18  To determine if the answer is correct, we firs...   \n",
       " 19  The question asks for the total number of plan...   \n",
       " \n",
       "     eval.answer_correctness.trace.id  eval.answer_correctness.trace.timestamp  \n",
       " 0   55686c9e51d19e8b7f4a0964f6662deb                            1745970235188  \n",
       " 1   3418e659d70b34fd44b669c2b7a5e05c                            1745970236575  \n",
       " 2   abce14431fde00298a1f50d28d9eaff7                            1745970237828  \n",
       " 3   a71d5e0b094650b37dda062a935523b1                            1745970239104  \n",
       " 4   3ffd558315ebdef8b7bfcc02c4e7f130                            1745970240263  \n",
       " 5   4f6c3acbe7c2a8bb9e01cb0d0551440e                            1745970241774  \n",
       " 6   af32e90a52807fd3cc170e59d5295def                            1745970243176  \n",
       " 7   e3f32e7c92c9bca7a2b6db2cd848556e                            1745970244748  \n",
       " 8   84570361b216a739edf9e100c6778abd                            1745970246305  \n",
       " 9   efdb967ccb26fb9344e93a48220d9bdf                            1745970247846  \n",
       " 10  085cee2a3c89cb00b64d0b338fce7f80                            1745970249412  \n",
       " 11  77977e07f3ff5a3abfe60130626d6aad                            1745970251221  \n",
       " 12  47f2db9856466444f4c7bfc4ebe66c67                            1745970252551  \n",
       " 13  fe37d31ba6c80b8f106801cd088157a4                            1745970257570  \n",
       " 14  c022bb29e9e7a5df68131f961daee680                            1745970258900  \n",
       " 15  237d9f367961ecf5f394faa648c1110c                            1745970260457  \n",
       " 16  52353ecb5c30c662ccec94d5fdaf7f67                            1745970261930  \n",
       " 17  b5c35953026f12ba68ce65276b14d509                            1745970263392  \n",
       " 18  9d58208057b792614919a4c497838662                            1745970268951  \n",
       " 19  8a654bca2eeda08a4c13d33a0bf2403d                            1745970270288  )"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweaks = { \n",
    "    \"Agent-C1GU0\": {\n",
    "            \"model_name\": \"gpt-4.1-mini\"\n",
    "    }\n",
    "}\n",
    "\n",
    "TWEAKS = tweaks\n",
    "\n",
    "arize_client.run_experiment(\n",
    "    space_id=ARIZE_SPACE_ID,\n",
    "    dataset_id=squad_qa_20,\n",
    "    task=task,\n",
    "    evaluators=[answer_correctness],\n",
    "    experiment_name=\"astra_v3_small_n3_gpt41mini_concise\",\n",
    "    exit_on_error=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langflow-dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
