{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure accuracy of agentic app with Arize and Langflow\n",
    "\n",
    "In this notebook we'll step through how to use open source tools [Arize](https://arize.com/) and [Langflow](https://www.langflow.org/) and to measure the accuracy of an agentic application.\n",
    "\n",
    "## Prepping a Dataset\n",
    "\n",
    "Let's start by gathering some example data from a standard question and answer benchmark. We'll use the Standford Question Answering Dataset (SQuAD).\n",
    "\n",
    "Available at [https://rajpurkar.github.io/SQuAD-explorer/](https://rajpurkar.github.io/SQuAD-explorer/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully\n",
      "Dataset loaded with 35 articles\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Download the file\n",
    "url = 'https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the download was successful\n",
    "if response.status_code == 200:\n",
    "    # Save the file locally\n",
    "    with open('dev-v2.0.json', 'w') as file:\n",
    "        json.dump(response.json(), file)\n",
    "    print(\"File downloaded successfully\")\n",
    "    \n",
    "    # Load the data\n",
    "    data = response.json()\n",
    "    print(f\"Dataset loaded with {len(data['data'])} articles\")\n",
    "else:\n",
    "    print(f\"Failed to download file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all articles from the dataset\n",
    "docs = []\n",
    "for record in data[\"data\"]:\n",
    "    text = \"\"\n",
    "    for paragraph in record[\"paragraphs\"]:\n",
    "        text += paragraph[\"context\"] + \"\\n\"\n",
    "    docs.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wikipedia articles in dataset: 35.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of wikipedia articles in dataset: {len(docs)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all questions and answers for each article\n",
    "qandas = []\n",
    "for record in data[\"data\"]:\n",
    "    for paragraph in record[\"paragraphs\"]:\n",
    "        for qa in paragraph[\"qas\"]:\n",
    "            if len(qa[\"answers\"]) > 0:\n",
    "                qandas.append((qa[\"question\"], qa[\"answers\"][0][\"text\"]))\n",
    "\n",
    "# there are about 6000 Q&A pairs in this data set.  \n",
    "# Let's shorten to 100 to make it easier to run our tests\n",
    "import random\n",
    "samples = random.sample(qandas, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What type of fossils were found in China?', 'Cambrian sessile frond-like fossil Stromatoveris')\n",
      "('Where do pharmacists acquire more preparation following pharmacy school?', 'a pharmacy practice residency')\n",
      "('What contributed to the decreased inequality between trained and untrained workers?', 'period of compression')\n"
     ]
    }
   ],
   "source": [
    "# Let's look at a couple examples of questions and answers\n",
    "print(samples[0])\n",
    "print(samples[1])\n",
    "print(samples[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install modules needed for the rest of this example\n",
    "\n",
    "We'll need the following modules to be available\n",
    "\n",
    "- `langflow` for rapidly designing AI workflows\n",
    "- `phoenix-arize` to run evals\n",
    "- `pandas` to format the data\n",
    "- `openai` for access to LLMs and embedding models\n",
    "\n",
    "If you don't already have these installed, go ahead and run the install commands below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: uv in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.5.15)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPython 3.11.7 interpreter at: \u001b[36m/opt/homebrew/opt/python@3.11/bin/python3.11\u001b[39m\n",
      "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
      "Activate with: \u001b[32msource .venv/bin/activate\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# uv requires a virtual environment to run\n",
    "!uv venv\n",
    "!source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install all the modules for the rest of the notebook\n",
    "!uv pip install langflow pandas openai arize -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our ground truth data to Arize\n",
    "\n",
    "Now that we have a set of questions and answers, we can use this to evaluate the quality of our agentic application.\n",
    "\n",
    "Let's upload this dataset to Phoenix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start by creating a dataframe with our Q&A pairs and save a copy\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(samples, columns=[\"question\", \"answer\"])\n",
    "\n",
    "# only run this line if you want to resave the dataframe\n",
    "df.to_csv(\"data/qa_pairs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What type of fossils were found in China?</td>\n",
       "      <td>Cambrian sessile frond-like fossil Stromatoveris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where do pharmacists acquire more preparation following pharmacy school?</td>\n",
       "      <td>a pharmacy practice residency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What contributed to the decreased inequality between trained and untrained workers?</td>\n",
       "      <td>period of compression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                              question  \\\n",
       "0                                            What type of fossils were found in China?   \n",
       "1             Where do pharmacists acquire more preparation following pharmacy school?   \n",
       "2  What contributed to the decreased inequality between trained and untrained workers?   \n",
       "\n",
       "                                             answer  \n",
       "0  Cambrian sessile frond-like fossil Stromatoveris  \n",
       "1                     a pharmacy practice residency  \n",
       "2                             period of compression  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# or just load from the csv provided\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/qa_pairs.csv\")\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "    display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to create dataset: name=squad_dataset, type=1 for space_id=U3BhY2U6MTg3OTg6RDY3Vg==",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFlightUnauthenticatedError\u001b[39m                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/envs/langflow-dev-env/lib/python3.12/site-packages/arize/experimental/datasets/core/client.py:459\u001b[39m, in \u001b[36mArizeDatasetsClient.create_dataset\u001b[39m\u001b[34m(self, space_id, dataset_name, dataset_type, data, convert_dict_to_json)\u001b[39m\n\u001b[32m    456\u001b[39m writer, metadata_reader = flight_client.do_put(\n\u001b[32m    457\u001b[39m     descriptor, tbl.schema, \u001b[38;5;28mself\u001b[39m.session.call_options\n\u001b[32m    458\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtbl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_chunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10_000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/envs/langflow-dev-env/lib/python3.12/site-packages/pyarrow/ipc.pxi:543\u001b[39m, in \u001b[36mpyarrow.lib._CRecordBatchWriter.__exit__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/envs/langflow-dev-env/lib/python3.12/site-packages/pyarrow/_flight.pyx:1238\u001b[39m, in \u001b[36mpyarrow._flight.MetadataRecordBatchWriter.close\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/envs/langflow-dev-env/lib/python3.12/site-packages/pyarrow/_flight.pyx:64\u001b[39m, in \u001b[36mpyarrow._flight.check_flight_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mFlightUnauthenticatedError\u001b[39m: Flight returned unauthenticated error, with message: auth-error: rpc error: code = PermissionDenied desc = Unable to authenticate. gRPC client debug context: UNKNOWN:Error received from peer ipv4:34.117.96.240:443 {grpc_message:\"auth-error: rpc error: code = PermissionDenied desc = Unable to authenticate\", grpc_status:16, created_time:\"2025-04-27T10:20:15.025-07:00\"}. Client context: OK",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     10\u001b[39m ARIZE_SPACE_ID = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mARIZE_SPACE_ID\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m client = ArizeDatasetsClient(api_key=ARIZE_API_KEY)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m dataset_id = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspace_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mARIZE_SPACE_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msquad_dataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGENERATIVE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/envs/langflow-dev-env/lib/python3.12/site-packages/arize/experimental/datasets/core/client.py:469\u001b[39m, in \u001b[36mArizeDatasetsClient.create_dataset\u001b[39m\u001b[34m(self, space_id, dataset_name, dataset_type, data, convert_dict_to_json)\u001b[39m\n\u001b[32m    467\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(res.dataset_id)\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    470\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to create dataset: name=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, type=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for space_id=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspace_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    471\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    473\u001b[39m     flight_client.close()\n",
      "\u001b[31mRuntimeError\u001b[39m: Failed to create dataset: name=squad_dataset, type=1 for space_id=U3BhY2U6MTg3OTg6RDY3Vg=="
     ]
    }
   ],
   "source": [
    "# now let's create a dataset in Arize\n",
    "from arize.experimental.datasets import ArizeDatasetsClient\n",
    "from arize.experimental.datasets.utils.constants import GENERATIVE\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "ARIZE_API_KEY = os.getenv(\"ARIZE_API_KEY\")\n",
    "ARIZE_SPACE_ID = os.getenv(\"ARIZE_SPACE_ID\")\n",
    "\n",
    "client = ArizeDatasetsClient(api_key=ARIZE_API_KEY)\n",
    "\n",
    "dataset_id = client.create_dataset(\n",
    "    space_id=ARIZE_SPACE_ID, \n",
    "    dataset_name=\"squad_dataset\",\n",
    "    dataset_type=GENERATIVE,\n",
    "    data=df\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¤ Uploading dataset...\n",
      "ðŸ’¾ Examples uploaded: http://localhost:6006/datasets/RGF0YXNldDoy/examples\n",
      "ðŸ—„ï¸ Dataset version ID: RGF0YXNldFZlcnNpb246Mg==\n"
     ]
    }
   ],
   "source": [
    "# for speed, let's also make a smaller dataset\n",
    "df_small = df.head(20)\n",
    "dataset = client.upload_dataset(\n",
    "    dataframe=df_small,\n",
    "    dataset_name=\"squad-dev-v2.0-x-small\",\n",
    "    input_keys=[\"question\"],\n",
    "    output_keys=[\"answer\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Langflow Flows from code\n",
    "\n",
    "In this section, we define a method to use the Langflow runtime to execute flows and return the results.\n",
    "\n",
    "You can find details on how to call these methods by clicking the API button in the upper right corner of the Langflow UI when a flow is open and you are editing it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to run a flow in Langflow\n",
    "# trigger flow via API\n",
    "import requests\n",
    "\n",
    "BASE_API_URL = \"http://127.0.0.1:7860\"\n",
    "\n",
    "def run_flow(input: str, flow_id: str, input_type: str = \"chat\", tweaks: dict = None):\n",
    "    \"\"\" Raises exceptions for non-200 status code from langflow response\n",
    "    \"\"\"\n",
    "    api_url = f\"{BASE_API_URL}/api/v1/run/{flow_id}\"\n",
    "\n",
    "    payload = {\n",
    "        \"input_value\": input,\n",
    "        \"output_type\": \"chat\",\n",
    "        \"input_type\": input_type,\n",
    "    }\n",
    "\n",
    "    if tweaks:\n",
    "        payload[\"tweaks\"] = tweaks\n",
    "\n",
    "    timeout = 10\n",
    "    attempts = 6\n",
    "    for i in range(attempts):\n",
    "        try:\n",
    "            response = requests.post(api_url, json=payload, timeout=timeout)\n",
    "            if response.status_code != 200:\n",
    "                raise requests.exceptions.RequestException(f\"Status code: {response.status_code}\")\n",
    "            return response\n",
    "        \n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"The flow request timed out. Attempt {i}, current timeout {timeout}.\")\n",
    "            timeout *= 2\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(e)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load our Wikipedia data into the vector database with a flow in Langflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_load_flow_id = \"d469424c-96da-44ae-b018-9b044b805144\"\n",
    "for i, doc in enumerate(docs):\n",
    "    run_flow(doc, data_load_flow_id, input_type=\"text\")\n",
    "    print(f\"Completed processing doc {i}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run an experiment with Langflow and Arize Phoenix\n",
    "\n",
    "1. Define a task to run the the a flow on the dataset\n",
    "2. Create an LLM to act as a judge\n",
    "3. Define an evaluator to measure the accuracy of the results\n",
    "4. Run the experiment and log the results to Arize Phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_FLOW_ID = \"feab8feb-9f27-4132-8aa6-265962e19144\"\n",
    "\n",
    "\n",
    "def task(dataset_row) -> str:\n",
    "    question = dataset_row[\"question\"]\n",
    "    response = run_flow(question, CHAT_FLOW_ID)\n",
    "    text = response.json()['outputs'][0]['outputs'][0]['results']['message'][\"text\"]\n",
    "    return text   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from phoenix.evals.models import OpenAIModel\n",
    "\n",
    "with open(\"openai_key.json\", \"r\") as file:\n",
    "    keys = json.load(file)\n",
    "\n",
    "openai_api_key = keys.get(\"openai_api_key\")\n",
    "openai.api_key = openai_api_key\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "judge_model = OpenAIModel(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "from phoenix.evals import (\n",
    "    QA_PROMPT_RAILS_MAP,\n",
    "    QA_PROMPT_TEMPLATE,\n",
    "    OpenAIModel,\n",
    "    llm_classify,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are given a question, an answer and reference text. You must determine whether the\n",
      "given answer correctly answers the question based on the reference text. Here is the data:\n",
      "    [BEGIN DATA]\n",
      "    ************\n",
      "    [Question]: {input}\n",
      "    ************\n",
      "    [Reference]: {reference}\n",
      "    ************\n",
      "    [Answer]: {output}\n",
      "    [END DATA]\n",
      "Your response must be a single word, either \"correct\" or \"incorrect\",\n",
      "and should not contain any text or characters aside from that word.\n",
      "\"correct\" means that the question is correctly and fully answered by the answer.\n",
      "\"incorrect\" means that the question is not correctly or only partially answered by the\n",
      "answer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(QA_PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.experiments.evaluators import create_evaluator\n",
    "\n",
    "@create_evaluator(name=\"Answer Correctness\", kind=\"LLM\")\n",
    "def answer_correctness(input, output, expected) -> int:\n",
    "\n",
    "    df_in = pd.DataFrame({\n",
    "        \"input\": input[\"question\"],\n",
    "        \"output\": output,\n",
    "        \"reference\": expected[\"answer\"]\n",
    "    }, index=[0])\n",
    "              \n",
    "    rails = list(QA_PROMPT_RAILS_MAP.values())\n",
    "    \n",
    "    eval_df = llm_classify(\n",
    "        data=df_in,\n",
    "        template=QA_PROMPT_TEMPLATE,\n",
    "        model=judge_model,\n",
    "        rails=rails,\n",
    "        provide_explanation=True,\n",
    "        run_sync=True,\n",
    "    )\n",
    "\n",
    "    label = eval_df[\"label\"][0]\n",
    "    explanation = eval_df[\"explanation\"][0]\n",
    "    score = 1 if label == \"correct\" else 0\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.experiments import run_experiment\n",
    "\n",
    "run_experiment(\n",
    "    dataset,\n",
    "    task=task,\n",
    "    evaluators=[answer_correctness],\n",
    "    experiment_name=\"Experiment 6 - long\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langflow-dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
